{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program name: ReadSIFTS_FilterPDBDIMER.ipynb \n",
    "This notebook notes down the detailed steps to obtain bacteria Homodimer/Heterodimer, Human Homodimer/Heterodimer structures from PDB. It can also be adapted to certain multimer for certain species from PDB.\n",
    "\n",
    "It starts from reading two SIFTS files (relatively \"stable\"): *pdb_chain_uniprot.csv* and *pdb_chain_tax.csv*; retrieve experimental method and resolution from PDB API services (*REST*); checks chain length; taxnomy information; and lastly, check chains in the first bioassembly by reading the header of PDB file. \n",
    "\n",
    ">- Run with python3.9\n",
    ">- Install pandas, biopython, pypdb\n",
    "\n",
    "Author: Haiqing Zhao, Honig Lab at Columbia University\n",
    "<br>Related other programs: ReadPDBreport_FindHeterodimer.py\n",
    "<br>Created: 08/11/2022\n",
    "<br>Last Update: 09/09/2023\n",
    "\n",
    "### Selecting conditions for a pure hetero- or homo-dimer of bacteria or human:\n",
    "1. All included proteins must come from one bacterial species or from human 9606 [using files *SIFTS_pdb_chain_taxonomy.csv*; *NCBI_taxonomy_bacteria_full_result.txt*];\n",
    "2. Number of chains =2; only one Uniprot protein for homodimer; two Uniprot proteins for heterodimer; sequence length(s) > 30aa;\n",
    "3. Resolution < 4.0(X-ray) or < 4.5(EM) $\\AA$;\n",
    "4. Select BioAssembly 1, 2chains, and the Author- or software-defined;\n",
    "5. Remove redundant dimers by keeping the structure of significantly-LONG total length, or better resolution; (significant: >2-fold than others)\n",
    "6. => *human_PDB_g2chains_hetero2uni_g30aa_reslgood_BU1_2chains_nochim_nonredun_2uni_05082023.csv*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pypdb\n",
    "from Bio.PDB.PDBParser import PDBParser\n",
    "import Bio.PDB as PDB\n",
    "\n",
    "localpathprefix = '/Users/hz2592/OneDrive - cumc.columbia.edu/WORK'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, read the two SIFTS files *pdb_chain_uniprot.csv*, *pdb_chain_taxonomy.csv* and filter from Uniprot and taxonomy perspective\n",
    "\n",
    "The two SIFTS files are downloaded from https://www.ebi.ac.uk/pdbe/docs/sifts/quick.html\n",
    "\n",
    "Remember to pre-process SIFTS files: run the following command to avoid misreading fields\n",
    ">`sed \"s/,/\\-/4\" pdb_chain_taxonomy.csv > pdb_chain_taxonomy.fixed.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the two SIFTS pdb_chain files in two  dictionaries\n",
    "### This block takes 7-8 min to run. \n",
    "\n",
    "SIFTS_pdb_chain_uniprot=localpathprefix+'/SIFTS_202111/pdb_chain_uniprot.csv'\n",
    "SIFTS_pdb_chain_taxonomy=localpathprefix+'/SIFTS_202111/pdb_chain_taxonomy.csv'\n",
    "#head pdb_chain_taxonomy.csv\n",
    "#PDB,CHAIN,TAX_ID,SCIENTIFIC_NAME\n",
    "#head pdb_chain_uniprot.csv\n",
    "#PDB,CHAIN,SP_PRIMARY,RES_BEG,RES_END,PDB_BEG,PDB_END,SP_BEG,SP_END\n",
    "\n",
    "df_SIFTS_chain_Uni = pd.read_csv(SIFTS_pdb_chain_uniprot,dtype=object,skiprows=1,usecols=['PDB','CHAIN','SP_PRIMARY','SP_BEG','SP_END']).fillna(0)\n",
    "df_SIFTS_chain_Uni = df_SIFTS_chain_Uni.rename(columns={'SP_PRIMARY': 'Uniprot'})\n",
    "\n",
    "dic_chain_Unis,dic_PDB_Chain_Unis={},{}\n",
    "for index, row in df_SIFTS_chain_Uni.iterrows():\n",
    "    pdb=row['PDB']\n",
    "    chainlength=int(row['SP_END'])-int(row['SP_BEG'])\n",
    "    if pdb in dic_PDB_Chain_Unis:\n",
    "        if row['CHAIN'] not in dic_PDB_Chain_Unis[pdb]:\n",
    "            dic_PDB_Chain_Unis[pdb].update({row['CHAIN']:[row['Uniprot'],chainlength]})\n",
    "        elif row['Uniprot'] not in dic_PDB_Chain_Unis[pdb][row['CHAIN']]:\n",
    "            dic_PDB_Chain_Unis[pdb][row['CHAIN']].extend([row['Uniprot'],chainlength])\n",
    "    else:\n",
    "        dic_PDB_Chain_Unis[pdb]={row['CHAIN']:[row['Uniprot'],chainlength]}\n",
    "\n",
    "dic_PDB_Taxs={}\n",
    "df_SIFTS_chain_Tax = pd.read_csv(SIFTS_pdb_chain_taxonomy,dtype=object,skiprows=1,usecols=['PDB','CHAIN','TAX_ID']) #.fillna(0)\n",
    "for index, row in df_SIFTS_chain_Tax.iterrows():\n",
    "    pdb=row['PDB']\n",
    "    if pdb in dic_PDB_Taxs:\n",
    "        if row['TAX_ID'] not in dic_PDB_Taxs[pdb]:\n",
    "            dic_PDB_Taxs[pdb].append(row['TAX_ID'])\n",
    "    else:\n",
    "        dic_PDB_Taxs[pdb]=[row['TAX_ID']]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: because all we require is that the chains of one PDB are from the same species, we checked the taxonomy at the PDB level. Here, one scenaro that we did not take into account is the cases where SIFTS_chain_Tax may have missed one chain's information. For example, 3pse, SIFT_chain_tax only contains chain B.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pre-filtering step: Define bacteria and human taxonomy \n",
    "#### Skip three blocks if already provided with the categorizedPDB_goodresolution file. \n",
    "#### This block takes 15-20min to run. To run, switch to code mode.\n",
    "#### Full bacteria taxID list is downloaded from https://www.ncbi.nlm.nih.gov/taxonomy?term=txid2%5BSubtree%5D&cmd=DetailsSearch; \n",
    "\n",
    "print(\"Number of PDBs:\",len(dic_PDB_Taxs))\n",
    "bacteria_taxlistfile = '/Users/hz2592/Dropbox/Methods/bacteria_CSV/NCBI_taxonomy_bacteria_full_result.txt'\n",
    "with open(bacteria_taxlistfile, \"r\") as filestream:\n",
    "    lines = filestream.readlines()\n",
    "    bacteria_taxlist = [line.rstrip() for line in lines]\n",
    "\n",
    "bacteria_PDBs=[];human_PDBs=[]\n",
    "for i in dic_PDB_Taxs:\n",
    "    if len(dic_PDB_Taxs[i]) ==1:\n",
    "        if dic_PDB_Taxs[i][0] in bacteria_taxlist:\n",
    "            bacteria_PDBs.append(i)\n",
    "        if dic_PDB_Taxs[i][0]== '9606':\n",
    "            human_PDBs.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pre-filtering step: from >2-chain PDB, define bacteria heteroPDB (2uni), bacteria homoPDB (1uni); same for human; select len ≥ 30aa\n",
    "#### Skip two blocks if already provided with the categorizedPDB_goodresolution file. \n",
    "#### This block takes 1min to run. To run, switch to code mode.\n",
    "\n",
    "bacteria_homoPDBs=[];bacteria_heteroPDBs=[]\n",
    "for pdb in bacteria_PDBs:\n",
    "    if pdb in dic_PDB_Chain_Unis:\n",
    "        if len(dic_PDB_Chain_Unis[pdb]) >= 2: \n",
    "            unis = [chainrecord[0] for chainrecord in dic_PDB_Chain_Unis[pdb].values()]\n",
    "            lengths = [chainrecord[1] for chainrecord in dic_PDB_Chain_Unis[pdb].values()]\n",
    "            if len(set(unis)) == 1 and all([length >= 30 for length in lengths]):\n",
    "                bacteria_homoPDBs.append(pdb)\n",
    "            if len(set(unis)) == 2 and all([length >= 30 for length in lengths]):\n",
    "                bacteria_heteroPDBs.append(pdb)\n",
    "print('Number of bacteria_homoPDBs, bacteria_heteroPDBs:',len(bacteria_homoPDBs), len(bacteria_heteroPDBs))\n",
    "\n",
    "human_homoPDBs=[];human_heter2merPDBs=[]\n",
    "for pdb in human_PDBs:\n",
    "    if pdb in dic_PDB_Chain_Unis:\n",
    "        if len(dic_PDB_Chain_Unis[pdb]) >= 2: \n",
    "            unis = [chainrecord[0] for chainrecord in dic_PDB_Chain_Unis[pdb].values()]\n",
    "            lengths = [chainrecord[1] for chainrecord in dic_PDB_Chain_Unis[pdb].values()]\n",
    "            if len(set(unis)) == 1 and all([length >= 30 for length in lengths]):\n",
    "                human_homoPDBs.append(pdb)\n",
    "            if len(set(unis)) == 2 and all([length >= 30 for length in lengths]):\n",
    "                human_heter2merPDBs.append(pdb)\n",
    "print('Number of human_homoPDBs, human_heter2merPDBs:',len(human_homoPDBs),len(human_heter2merPDBs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pre-filtering step: from above, generate good resolution lists for human/bacteria_hetero/homo: x-ray/EM < 4/4.5 å\n",
    "#### Write categorizedPDB_goodresolution files\n",
    "#### Skip to next block if already provided with the filtered_resolution file. \n",
    "#### This block takes 40-45 min to run. To run, switch to code mode.\n",
    "\n",
    "def get_expmethod_reslution(pdbid):\n",
    "    PDB_info = pypdb.get_entity_info(pdbid)\n",
    "    if PDB_info != None:\n",
    "        try:\n",
    "            PDB_info = PDB_info['rcsb_entry_info']\n",
    "            if PDB_info['selected_polymer_entity_types']=='Protein (only)' and (PDB_info['experimental_method'] in ['X-ray','ELECTRON MICROSCOPY','EM']) and PDB_info['resolution_combined'] != None:\n",
    "                return PDB_info['experimental_method'],PDB_info['resolution_combined'][0]\n",
    "            else: return None,None\n",
    "        except (KeyError, TypeError):\n",
    "            print('KeyError or TyperError:',pdbid)\n",
    "            return None, None\n",
    "    else:\n",
    "        print('Problematic PDB:',pdbid)\n",
    "        return None,None\n",
    "\n",
    "def select_goodresl_PDB_writefile(inputPDBlist,outfile):\n",
    "    outPDB_resl={}\n",
    "    for pdb in inputPDBlist:\n",
    "        method,resolution = get_expmethod_reslution(pdb)\n",
    "        if (method == 'X-ray' and resolution <= 4) or (method == 'ELECTRON MICROSCOPY' and resolution <= 4.5) or (method == 'EM' and resolution <= 4.5):\n",
    "            outPDB_resl.update({pdb:resolution})   \n",
    "    with open(outfile, 'w') as f:\n",
    "        f.write(\"%s,%s\\n\"%(\"PDBID\",\"Resolution\"))\n",
    "        for key in outPDB_resl.keys():\n",
    "            f.write(\"%s,%s\\n\"%(key,outPDB_resl[key]))\n",
    "    print(\"Selected PDB number from/to:\",len(inputPDBlist),len(outPDB_resl))\n",
    "    return\n",
    "\n",
    "bacteria_homoPDBs_g2chains_resl_file='/Users/hz2592/WORK/SIFTS_202111/PDB_resl/bacteria_homoPDBs_g2chains_g30aa_reslgood_05092023.csv'\n",
    "human_homoPDBs_g2chains_resl_file='/Users/hz2592/WORK/SIFTS_202111/PDB_resl/human_homoPDBs_g2chains_g30aa_reslgood_05092023.csv'\n",
    "human_heter2merPDBs_g2chains_resl_file='/Users/hz2592/WORK/SIFTS_202111/PDB_resl/human_heter2merPDBs_g2chains_g30aa_reslgood_05092023.csv'\n",
    "bacteria_heter2merPDBs_g2chains_resl_file='/Users/hz2592/WORK/SIFTS_202111/PDB_resl/bacteria_heter2merPDBs_g2chains_g30aa_reslgood_05092023.csv'\n",
    "\n",
    "select_goodresl_PDB_writefile(bacteria_homoPDBs,bacteria_homoPDBs_g2chains_resl_file)\n",
    "select_goodresl_PDB_writefile(human_homoPDBs,human_homoPDBs_g2chains_resl_file)\n",
    "select_goodresl_PDB_writefile(human_heter2merPDBs,human_heter2merPDBs_g2chains_resl_file)\n",
    "select_goodresl_PDB_writefile(bacteria_heteroPDBs,bacteria_heter2merPDBs_g2chains_resl_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved categorizedPDB_goodresolution files and read to dictionaries.\n",
    "\n",
    "bacteria_homoPDBs_g2chains_resl_file=localpathprefix+'/SIFTS_202111/PDB_resl/bacteria_homoPDBs_g2chains_g30aa_reslgood_05092023.csv'\n",
    "human_homoPDBs_g2chains_resl_file=localpathprefix+'/SIFTS_202111/PDB_resl/human_homoPDBs_g2chains_g30aa_reslgood_05092023.csv'\n",
    "human_heter2merPDBs_g2chains_resl_file=localpathprefix+'/SIFTS_202111/PDB_resl/human_heter2merPDBs_g2chains_g30aa_reslgood_05092023.csv'\n",
    "bacteria_heter2merPDBs_g2chains_resl_file=localpathprefix+'/SIFTS_202111/PDB_resl/bacteria_heter2merPDBs_g2chains_g30aa_reslgood_05092023.csv'\n",
    "\n",
    "human_heter2merPDBs_resl = pd.read_csv(human_heter2merPDBs_g2chains_resl_file).set_index('PDBID').to_dict()['Resolution']\n",
    "bacteria_heter2merPDBs_resl = pd.read_csv(bacteria_heter2merPDBs_g2chains_resl_file).set_index('PDBID').to_dict()['Resolution']\n",
    "bacteria_homoPDBs_resl = pd.read_csv(bacteria_homoPDBs_g2chains_resl_file).set_index('PDBID').to_dict()['Resolution']\n",
    "human_homoPDBs_resl = pd.read_csv(human_homoPDBs_g2chains_resl_file).set_index('PDBID').to_dict()['Resolution']\n",
    "\n",
    "dict_PDB_resl = bacteria_homoPDBs_resl | human_homoPDBs_resl | human_heter2merPDBs_resl | bacteria_heter2merPDBs_resl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bacteria_homoPDBs_2chains, bacteria_heter2merPDBs_2chains:  16166 651\n",
      "Number of human_homoPDBs_2chains, human_heter2merPDBs_2chains:  9455 1202\n",
      "Number of human_heter2merPDBs_g2chains:  2637\n"
     ]
    }
   ],
   "source": [
    "# Select PDBs with only TWO chains for a pure dimer list\n",
    "\n",
    "bacteria_homoPDBs_2chains=[]\n",
    "for pdb in bacteria_homoPDBs_resl:\n",
    "    if pdb in dic_PDB_Chain_Unis:\n",
    "        if len(dic_PDB_Chain_Unis[pdb]) == 2: \n",
    "            bacteria_homoPDBs_2chains.append(pdb)\n",
    "\n",
    "human_homoPDBs_2chains=[]\n",
    "for pdb in human_homoPDBs_resl:\n",
    "    if pdb in dic_PDB_Chain_Unis:\n",
    "        if len(dic_PDB_Chain_Unis[pdb]) == 2: \n",
    "            human_homoPDBs_2chains.append(pdb)\n",
    "\n",
    "human_heter2merPDBs_2chains=[]\n",
    "for pdb in human_heter2merPDBs_resl:\n",
    "    if pdb in dic_PDB_Chain_Unis:\n",
    "        if len(dic_PDB_Chain_Unis[pdb]) == 2: \n",
    "            human_heter2merPDBs_2chains.append(pdb)\n",
    "\n",
    "bacteria_heter2merPDBs_2chains=[]\n",
    "for pdb in bacteria_heter2merPDBs_resl:\n",
    "    if pdb in dic_PDB_Chain_Unis:\n",
    "        if len(dic_PDB_Chain_Unis[pdb]) == 2: \n",
    "            bacteria_heter2merPDBs_2chains.append(pdb)\n",
    "\n",
    "print('Number of bacteria_homoPDBs_2chains, bacteria_heter2merPDBs_2chains: ',len(bacteria_homoPDBs_2chains),len(bacteria_heter2merPDBs_2chains))\n",
    "print('Number of human_homoPDBs_2chains, human_heter2merPDBs_2chains: ',len(human_homoPDBs_2chains),len(human_heter2merPDBs_2chains))\n",
    "\n",
    "human_heter2merPDBs_g2chains = human_heter2merPDBs_resl.keys()\n",
    "print('Number of human_heter2merPDBs_g2chains: ',len(human_heter2merPDBs_g2chains))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check bio-molecule 1 (bio-unit 1, bio-assembly 1)\n",
    "At the time being, the PDB API service either REST or GraphQL could not provide exact chain IDs that are in the first bio-assembly. \n",
    "The next block is written to do this job, by reading the header of PDB file. The REMARK 350 session marks the author- or software-defined bio-assembly, and described what transformation was applied to what chains to generate it. \n",
    "\n",
    "Note that the number of \"APPLY\"s is equal to the number of MODEL in pdb1 file. So one should calculate IFC across models since these are considered as a bio-assembly. Example: when two APPLYs of transformation happen in bio-assembly 1. \n",
    "\n",
    "To run the below block, one needs to download needed PDB files to local machine. \n",
    ">Run command to download PDB:\n",
    ">`wget http://www.rcsb.org/pdb/files/XXXX.pdb`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to read PDB header to obtain BU1 author_bu1, software_bu1, chainIDs and their resolved seq_length information\n",
    "#### Select PDBs with only 2chains in biounit 1\n",
    "#### Skip three blocks if provided with PDBread files.\n",
    "\n",
    "def get_auth_software_bu1(inputPDBs):\n",
    "    PDBdb_dir='/Volumes/bh_lab_data/shares/databases/pdb/';dic_output={}\n",
    "    for pdb in inputPDBs:\n",
    "        auth_oligstate_biomol1=None;software_oligstate_biomol1=None;chains_biomol1=[]\n",
    "        try:\n",
    "            pdbfile=open(PDBdb_dir+pdb+'.pdb','r')\n",
    "            #pdbfile = open('/Volumes/bh_lab_data/shares/databases/pdb/1axi.pdb','r')\n",
    "        except FileNotFoundError:\n",
    "            print('Not available complexes; Skip',pdb)\n",
    "            continue\n",
    "        for line in pdbfile:\n",
    "            if \"REMARK 350 BIOMOLECULE:\" in line:\n",
    "                if line.split(':')[1].strip()==\"1\":\n",
    "                    biomol=1\n",
    "                else:\n",
    "                    biomol=line.split(':')[1].strip()\n",
    "                    break\n",
    "            if \"REMARK 350 AUTHOR DETERMINED BIOLOGICAL UNIT:\" in line:\n",
    "                if biomol==1:\n",
    "                    auth_oligstate_biomol1=line.split(':')[1].strip()\n",
    "            if \"REMARK 350 SOFTWARE DETERMINED QUATERNARY STRUCTURE:\" in line:\n",
    "                if biomol==1:\n",
    "                    software_oligstate_biomol1=line.split(':')[1].strip()\n",
    "            if 'REMARK 350 APPLY THE FOLLOWING TO CHAINS:' in line or 'REMARK 350 IN ADDITION APPLY THE FOLLOWING TO CHAINS' in line or 'REMARK 350 AND CHAINS' in line:\n",
    "                if biomol==1:\n",
    "                    chains_biomol1 = chains_biomol1+line.split(':')[1].strip().split(', ')\n",
    "            if \"REMARK 500\" in line: \n",
    "                break\n",
    "        if all(i in dic_PDB_Chain_Unis[pdb].keys() for i in chains_biomol1) and len(chains_biomol1)==2:\n",
    "            structure = PDBParser().get_structure('', PDBdb_dir+pdb+'.pdb')\n",
    "            reslv_seqs_biomol1 = []\n",
    "            for i in chains_biomol1:\n",
    "                reslv_seq = len([_ for _ in structure[0][i].get_residues() if PDB.is_aa(_)])\n",
    "                reslv_seqs_biomol1.append(reslv_seq)\n",
    "            dic_output.update({pdb:[auth_oligstate_biomol1,software_oligstate_biomol1,chains_biomol1,reslv_seqs_biomol1]})\n",
    "            #except KeyError: print ('PDBfile chain reading error:', pdb,chains_biomol1) \n",
    "    return dic_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get BU1's Author-oligomer, software-oligomer, chainIDs\n",
    "#### bac_homo takes 6-7min; human_homo takes 2-3min; \n",
    "#### human heterodimers takes 8min; bac_homo takes 50min. \n",
    "\n",
    "human_heterPDBs_2chains_dic_auth_sotware_bu1_2chains = get_auth_software_bu1(human_heter2merPDBs_2chains)\n",
    "bacteria_heterPDBs_2chains_dic_auth_sotware_bu1_2chains = get_auth_software_bu1(bacteria_heter2merPDBs_2chains)\n",
    "human_homoPDBs_2chains_dic_auth_sotware_bu1_2chains = get_auth_software_bu1(human_homoPDBs_2chains)\n",
    "bacteria_homoPDBs_2chains_dic_auth_sotware_bu1_2chains = get_auth_software_bu1(bacteria_homoPDBs_2chains)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional test for special PDB cases\n",
    "\n",
    "test_list =['1A22','2D7T','4NUG','4NUJ','4NWU','4O5L','5EWI','5IDN','5M9O','5SZH','5SZI','5SZJ','5VSI','5W6C','5WHJ','6D4P','6DC4','6TX3','6U07','6W2L','6XI7','6ZBK','6ZUE','7E2I','7F6L','7FGM','7MNR','7MON','7NJ1','7PW9','7S0U','7SCW','7SHQ','7TYR','7UZU','7V8F','7VG7','7VV9','7VVB','8A8M']\n",
    "for pdb in test_list:\n",
    "    pdb=pdb.lower()\n",
    "    try:\n",
    "        dic_PDB_Chain_Unis[pdb]\n",
    "    except KeyError:\n",
    "        print(\"Not in SIFTS_pdbchain_Uniprot:\",pdb)\n",
    "    try:\n",
    "        dic_PDB_Taxs[pdb]\n",
    "    except KeyError:\n",
    "        print(\"Not in SIFTS_pdbchain_Tax:\",pdb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write PDB-head-read information to files\n",
    "\n",
    "def writeReslSeq_file(inputPDBdict,outfile):\n",
    "    with open(outfile, 'w') as f:\n",
    "        f.write(\"%s,%s,%s,%s,%s,%s,%s\\n\"%(\"PDBID\",\"Auth_bu1\",\"Software_bu1\",\"Chain1\",\"Chain2\",\"rslvSeq1\",\"rslvSeq2\"))\n",
    "        for key in inputPDBdict.keys():\n",
    "            f.write(\"%s,%s,%s,%s,%s,%s,%s\\n\"%(key,inputPDBdict[key][0],inputPDBdict[key][1],inputPDBdict[key][2][0],inputPDBdict[key][2][1],inputPDBdict[key][3][0],inputPDBdict[key][3][0],))\n",
    "    return\n",
    "\n",
    "#Auth_bu1,Software_bu1,Resolution,Chain1,Chain2,Tax1,Tax2,Uni1,Uni2,rslvSeq1,rslvSeq2\n",
    "#{pdb:[auth_oligstate_biomol1,software_oligstate_biomol1,chains_biomol1,reslv_seqs_biomol1]}\n",
    "\n",
    "bacteria_homoPDBs_2chains_readPDB_file=localpathprefix+'/SIFTS_202111/PDB_resl/bacteria_homoPDBs_2chains_g30aa_reslgood_PDBread_BU1_05102023.csv'\n",
    "bacteria_heteroPDBs_2chains_readPDB_file=localpathprefix+'/SIFTS_202111/PDB_resl/bacteria_heteroPDBs_2chains_g30aa_reslgood_PDBread_BU1_05102023.csv'\n",
    "human_heteroPDBs_2chains_readPDB_file=localpathprefix+'/SIFTS_202111/PDB_resl/human_heteroPDBs_2chains_g30aa_reslgood_PDBread_BU1_05102023.csv'\n",
    "human_homoPDBs_2chains_readPDB_file=localpathprefix+'/SIFTS_202111/PDB_resl/human_homoPDBs_2chains_g30aa_reslgood_PDBread_BU1_05102023.csv'\n",
    "\n",
    "writeReslSeq_file(human_heterPDBs_2chains_dic_auth_sotware_bu1_2chains,human_heteroPDBs_2chains_readPDB_file)\n",
    "writeReslSeq_file(human_homoPDBs_2chains_dic_auth_sotware_bu1_2chains,human_homoPDBs_2chains_readPDB_file)\n",
    "writeReslSeq_file(bacteria_homoPDBs_2chains_dic_auth_sotware_bu1_2chains,bacteria_homoPDBs_2chains_readPDB_file)\n",
    "writeReslSeq_file(bacteria_heterPDBs_2chains_dic_auth_sotware_bu1_2chains,bacteria_heteroPDBs_2chains_readPDB_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove PPI Uniprot-pair redundancy; Remove chimeria proteins; Remove short proteins\n",
    "## by keeping the structure that has significantly-LONG sequence or better resolution  \n",
    "\n",
    "df_SIFTS_chain_Tax['PDBchain'] = df_SIFTS_chain_Tax['PDB'].astype(str) + df_SIFTS_chain_Tax['CHAIN'].astype(str)\n",
    "SIFTS_chain_tax_avail = df_SIFTS_chain_Tax['PDBchain'].to_list()\n",
    "\n",
    "def remove_redundancy_dimer(PDBs_2chains_dic_auth_sotware_bu1_2chains,olig='hetero'):\n",
    "    PDBs_2chains_bu1_2chains_nonredun={};chimera_list=[]\n",
    "    for pdb in PDBs_2chains_dic_auth_sotware_bu1_2chains.keys():\n",
    "        if 'DIMERIC' not in PDBs_2chains_dic_auth_sotware_bu1_2chains[pdb][0:2]: continue\n",
    "        [chain1,chain2]=PDBs_2chains_dic_auth_sotware_bu1_2chains[pdb][2][0:2]\n",
    "        [len1,len2]=PDBs_2chains_dic_auth_sotware_bu1_2chains[pdb][3][0:2]\n",
    "        totallen = len1+len2\n",
    "        uni1,uni2=dic_PDB_Chain_Unis[pdb][chain1][0],dic_PDB_Chain_Unis[pdb][chain2][0]\n",
    "        unis=[uni1,uni2]\n",
    "        if (len(dic_PDB_Chain_Unis[pdb][chain1]) != 2) or (len(dic_PDB_Chain_Unis[pdb][chain2]) != 2): \n",
    "            print(\"Chimera chain found in\",pdb,'; SKIP');chimera_list.append(pdb)\n",
    "            continue\n",
    "        # confirm chains are those with NCBI-taxnomoyID, not others \n",
    "        if (pdb+chain1 not in SIFTS_chain_tax_avail) or (pdb+chain2 not in SIFTS_chain_tax_avail):\n",
    "            print (\"Tax not covered in SIFTS_chain_tax:\",pdb,'; SKIP')\n",
    "            continue\n",
    "        if olig=='hetero':\n",
    "            if chain1 == chain2 or uni1==uni2: \n",
    "                print (\"Identical_chainID or HOMOdimer in \",pdb,chain1,chain2,uni1,uni2,'; SKIP' ); \n",
    "                continue\n",
    "        else:\n",
    "            if chain1 == chain2 or uni1!=uni2: \n",
    "                print (\"Identical_chainID or HETEROdimer in \",pdb,chain1,chain2,uni1,uni2,'; SKIP');\n",
    "                continue\n",
    "        if len1 < 30 or len2 < 30: \n",
    "            print (\"Resvl seq len shorter than 30: \",pdb,chain1,chain2,len1,len2,'; SKIP' ); \n",
    "            continue\n",
    "        resl = dict_PDB_resl[pdb]\n",
    "        sorted_unis = tuple(sorted(unis))\n",
    "        if sorted_unis in PDBs_2chains_bu1_2chains_nonredun:\n",
    "            if totallen > 2*PDBs_2chains_bu1_2chains_nonredun[sorted_unis][2]:\n",
    "                PDBs_2chains_bu1_2chains_nonredun.update({sorted_unis:[pdb,resl,totallen]})\n",
    "            elif dict_PDB_resl[pdb] < PDBs_2chains_bu1_2chains_nonredun[sorted_unis][1]:\n",
    "                PDBs_2chains_bu1_2chains_nonredun.update({sorted_unis:[pdb,resl,totallen]})\n",
    "        else:\n",
    "            PDBs_2chains_bu1_2chains_nonredun.update({sorted_unis:[pdb,resl,totallen]})\n",
    "    return PDBs_2chains_bu1_2chains_nonredun \n",
    "\n",
    "\n",
    "human_heterPDBs_2chains_bu1DI_2chains_nonredun_dic = remove_redundancy_dimer(human_heterPDBs_2chains_dic_auth_sotware_bu1_2chains)\n",
    "print(\"Number of human_heterPDBs_2chains_bu1_2chains_nonredun:\",len(human_heterPDBs_2chains_bu1_2chains_nonredun_dic))\n",
    "human_heterPDBs_2chains_bu1DI_2chains_nonredun_list = [i[0] for i in human_heterPDBs_2chains_bu1DI_2chains_nonredun_dic.values()]\n",
    "\n",
    "bacteria_heterPDBs_2chains_bu1DI_2chains_nonredun_dic = remove_redundancy_dimer(bacteria_heterPDBs_2chains_dic_auth_sotware_bu1_2chains)\n",
    "print(\"Number of bacteria_heterPDBs_2chains_bu1DI_2chains_nonredun_dic:\",len(bacteria_heterPDBs_2chains_bu1DI_2chains_nonredun_dic))\n",
    "bacteria_heterPDBs_2chains_bu1DI_2chains_nonredun_list = [i[0] for i in bacteria_heterPDBs_2chains_bu1DI_2chains_nonredun_dic.values()]\n",
    "\n",
    "human_homoPDBs_2chains_bu1DI_2chains_nonredun_dic = remove_redundancy_dimer(human_homoPDBs_2chains_dic_auth_sotware_bu1_2chains,'homo')\n",
    "print(\"Number of human_homoPDBs_2chains_bu1DI_2chains_nonredun_dic:\",len(human_homoPDBs_2chains_bu1DI_2chains_nonredun_dic))\n",
    "human_homoPDBs_2chains_bu1DI_2chains_nonredun_list = [i[0] for i in human_homoPDBs_2chains_bu1DI_2chains_nonredun_dic.values()]\n",
    "\n",
    "bacteria_homoPDBs_2chains_bu1DI_2chains_nonredun_dic = remove_redundancy_dimer(bacteria_homoPDBs_2chains_dic_auth_sotware_bu1_2chains,'homo')\n",
    "print(\"Number of bacteria_homoPDBs_2chains_bu1DI_2chains_nonredun_dic:\",len(bacteria_homoPDBs_2chains_bu1DI_2chains_nonredun_dic))\n",
    "bacteria_homoPDBs_2chains_bu1DI_2chains_nonredun_list = [i[0] for i in bacteria_homoPDBs_2chains_bu1DI_2chains_nonredun_dic.values()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write finally selected categrized PDBDIMER list into csv files\n",
    "\n",
    "def write_finalfile(selectedlist,input_2chains_nonredun_dic_auth_sotware_bu1,outputfile):\n",
    "    with open(outputfile, 'w') as f:\n",
    "        column=\"PDBID,Auth_bu1,Software_bu1,Resolution,Chain1,Chain2,Tax1,Tax2,Uni1,Uni2,rslvSeq1,rslvSeq2\"\n",
    "        f.write(\"%s\\n\"%(column))\n",
    "        for pdb in sorted(selectedlist):\n",
    "            [chain1,chain2] = input_2chains_nonredun_dic_auth_sotware_bu1[pdb][2][0:2]\n",
    "            [seq1,seq2] = input_2chains_nonredun_dic_auth_sotware_bu1[pdb][3][0:2]\n",
    "            uni1,uni2 = dic_PDB_Chain_Unis[pdb][chain1][0],dic_PDB_Chain_Unis[pdb][chain2][0]\n",
    "            f.write(\"%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s\\n\"%(pdb,input_2chains_nonredun_dic_auth_sotware_bu1[pdb][0],input_2chains_nonredun_dic_auth_sotware_bu1[pdb][1],\\\n",
    "                dict_PDB_resl[pdb],chain1,chain2,dic_PDB_Taxs[pdb][0],dic_PDB_Taxs[pdb][0],uni1,uni2,seq1,seq2))\n",
    "    return\n",
    "\n",
    "human_heteroPDBs_2chains_resl_bu1DI_nonredun_file = localpathprefix+'/PDB_MI/HumanPDB_Hetero2mer/human_PDB_2chains_hetero2uni_g30aa_reslgood_BU1DI_2chains_nochim_nonredun_2uni_05112023.csv'\n",
    "write_finalfile(human_heterPDBs_2chains_bu1DI_2chains_nonredun_list,human_heterPDBs_2chains_dic_auth_sotware_bu1_2chains,human_heteroPDBs_2chains_resl_bu1DI_nonredun_file)\n",
    "\n",
    "bacteria_heteroPDBs_2chains_resl_nonredun_bu1DI_file = localpathprefix+'/PDB_MI/BacteriaPDB_Hetero2mer/bacteria_PDB_2chains_hetero2uni_g30aa_reslgood_BU1DI_2chains_nochim_nonredun_2uni_05112023.csv'\n",
    "write_finalfile(bacteria_heterPDBs_2chains_bu1DI_2chains_nonredun_list,bacteria_heterPDBs_2chains_dic_auth_sotware_bu1_2chains,bacteria_heteroPDBs_2chains_resl_nonredun_bu1DI_file)\n",
    "\n",
    "human_homoPDBs_2chains_resl_nonredun_bu1DI_file = localpathprefix+'/PDB_MI/HumanPDB_Homo2mer/human_PDB_2chains_1uni_g30aa_reslgood_BU1DI_2chains_nochim_nonredun_1uni_05112023.csv'\n",
    "write_finalfile(human_homoPDBs_2chains_bu1DI_2chains_nonredun_list,human_homoPDBs_2chains_dic_auth_sotware_bu1_2chains,human_homoPDBs_2chains_resl_nonredun_bu1DI_file)\n",
    "\n",
    "bacteria_homoPDBs_2chains_resl_nonredun_bu1DI_file = localpathprefix+'/PDB_MI/BacteriaPDB_Homo2mer/bacteria_PDB_2chains_1uni_g30aa_reslgood_BU1DI_2chains_nochim_nonredun_1uni_05112023.csv'\n",
    "write_finalfile(bacteria_homoPDBs_2chains_bu1DI_2chains_nonredun_list,bacteria_homoPDBs_2chains_dic_auth_sotware_bu1_2chains,bacteria_homoPDBs_2chains_resl_nonredun_bu1DI_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52167105d05fe3c13ef02ba1193de6c7febc86d95095f0bea42c203f3a341f90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
